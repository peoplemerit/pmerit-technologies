# AIXORD for LLaMA

## Meta AI Governance Framework

### A Complete Guide to Structured Human-AI Collaboration with LLaMA Models

---

**Version:** 4.2
**Platform:** LLaMA (Meta) — All Variants
**Classification:** Human-Facing Educational Document

---

# Dedication

To every developer, entrepreneur, and creator who has lost hours of work
to forgotten context, reversed decisions, and AI conversations that went nowhere.

This framework exists because chaos is optional.

To my wife and children — you deserve all of me, always. You called for
my time and attention — rightfully so — but instead, you made space. You
left daddy alone, not because you had to, but because you believed in the mission.
Your sacrifice, patience, and quiet strength made this book possible.

This is our shared creation. Thank you — for everything.

---

# Table of Contents

1. Introduction to AIXORD
2. What Makes AIXORD Different
3. The Authority Model
4. Understanding the AIXORD Formula
5. The Three Kingdoms
6. Gates and Checkpoints
7. Working with LLaMA Models
8. LLaMA-Specific Considerations
9. Getting Started: The Setup Sequence
10. Day-to-Day Operations
11. Quality Assurance
12. Session Management and Continuity
13. Troubleshooting Common Issues
14. Best Practices for LLaMA Users
15. Quick Reference Guide
16. Appendix: Product Information

---

# Chapter 1: Introduction to AIXORD

## What is AIXORD?

AIXORD — AI Execution Order — is a comprehensive governance framework designed to transform chaotic AI conversations into structured, productive collaboration. Born from the frustration of lost context, reversed decisions, and AI interactions that went nowhere, AIXORD provides the structure and discipline needed to get real work done with AI assistants.

At its core, AIXORD is a methodology. It adapts principles from military operations orders (OPORDs) and project management frameworks to create a clear, repeatable process for working with AI. Whether you're building software, writing documents, planning projects, or conducting research, AIXORD provides the scaffolding to keep everything organized and moving forward.

## The Problem AIXORD Solves

Anyone who has worked extensively with AI assistants has experienced the frustration of:

**Lost Context**: You explain your project requirements in detail, only to have the AI forget crucial information a few messages later. You find yourself repeating the same explanations over and over.

**Reversed Decisions**: You and the AI agree on an approach, but three turns later, the AI suggests something completely different, seemingly forgetting what was already decided.

**Scope Creep**: A simple request expands into something much larger as the AI enthusiastically adds features, approaches, or considerations that weren't asked for.

**Session Discontinuity**: You return to continue your work the next day, but there's no good way to pick up where you left off. All that context is gone.

**Quality Inconsistency**: Sometimes the AI produces excellent work; other times, the same request yields mediocre results. There's no systematic way to ensure quality.

AIXORD addresses each of these problems through explicit governance, clear role definitions, mandatory checkpoints, and structured session management.

## Who Should Use AIXORD?

AIXORD is designed for anyone who needs to accomplish meaningful work with AI assistance:

**Software Developers** building applications, debugging code, or architecting systems.

**Entrepreneurs** planning business strategies, creating content, or managing projects.

**Researchers** conducting literature reviews, analyzing data, or synthesizing information.

**Writers** creating long-form content, editing documents, or developing narratives.

**Project Managers** organizing tasks, tracking deliverables, and coordinating work.

**Students** working on complex assignments, learning new subjects, or preparing presentations.

If you've ever wished your AI conversations were more productive, more structured, and more reliable, AIXORD is for you.

---

# Chapter 2: What Makes AIXORD Different

## Beyond Simple Prompting

Most approaches to working with AI focus on prompt engineering — crafting the perfect request to get a good response. While prompt engineering is valuable, it treats each interaction as isolated. AIXORD recognizes that real work happens over time, across multiple sessions, with accumulated context and decisions.

AIXORD is not just about getting better responses. It's about building a sustainable working relationship with AI that produces consistent, high-quality results across extended projects.

## The Governance Philosophy

AIXORD operates on a fundamental principle: **structure enables freedom**. By establishing clear boundaries, roles, and processes, AIXORD paradoxically makes AI more useful, not less.

Think of it like the rules of a game. Without rules, there's no game — just chaos. But with clear rules, players can focus on strategy and execution. AIXORD provides the rules that make productive AI collaboration possible.

## Key Differentiators

**Explicit Authority**: AIXORD clearly defines who decides what. There's no ambiguity about whether the human or the AI is making a particular decision.

**State Management**: AIXORD tracks the current state of your project — what phase you're in, what decisions have been made, what's been verified. This state persists and carries forward.

**Gate-Based Progression**: Work moves forward through explicit gates that ensure requirements are met before proceeding. No skipping steps.

**Quality Dimensions**: AIXORD defines specific quality criteria that every deliverable must meet. Quality isn't subjective — it's measured against defined standards.

**Session Continuity**: AIXORD provides mechanisms for ending sessions cleanly and resuming work later without losing context.

---

# Chapter 3: The Authority Model

## The Three Roles

AIXORD defines three distinct roles with clear responsibilities:

### The Director (You)

The Director is always the human. As Director, you hold supreme authority over the project. Your responsibilities include:

**Deciding What**: You determine what the project should accomplish. You set objectives, define scope, and establish success criteria.

**Approval Authority**: Nothing happens without your approval. The AI cannot execute work unless you explicitly authorize it.

**Outcome Ownership**: You own the results. Good or bad, the outcomes of the project are your responsibility.

The Director role exists because AI should assist human work, not replace human judgment. AIXORD enforces this principle structurally.

### The Architect (AI Advisory Role)

When operating in Architect mode, the AI provides recommendations and analysis. The Architect:

**Recommends How**: Given your objectives, the Architect suggests approaches, analyzes options, and proposes solutions.

**Analyzes and Specifies**: The Architect breaks down complex requirements, identifies dependencies, and creates specifications.

**Advises on Risk**: The Architect identifies potential problems, trade-offs, and considerations you should be aware of.

The Architect never executes — only advises. This separation ensures you maintain control over what actually gets done.

### The Commander (AI Execution Role)

When authorized to execute, the AI operates as Commander:

**Executes Approved Work**: The Commander implements what the Director has approved, following the specifications developed by the Architect.

**Operates Within Bounds**: Execution is constrained to what was approved. No scope expansion. No creative interpretation.

**Reports Results**: The Commander reports what was done, enabling the Director to verify and approve the results.

## The Approval Grammar

For execution to proceed, the Director must provide explicit approval. AIXORD defines specific phrases that grant execution authority:

"APPROVED" — Authorizes the proposed action.

"APPROVED: [specific scope]" — Authorizes only the specified portion.

"EXECUTE" or "DO IT" — Direct authorization to proceed.

"YES, PROCEED" — Explicit confirmation of intent.

Importantly, casual affirmations do NOT grant execution authority:

"Looks good" — Too ambiguous.

"Fine" or "OK" — Not explicit enough.

"Sure" — Could mean many things.

Thumbs up or similar reactions — Not explicit approval.

If the AI receives an ambiguous response, it must request clarification rather than assuming approval. This prevents the frustrating situation where the AI proceeds with something you didn't actually intend to authorize.

## Silence Means Stop

In AIXORD, silence equals halt. If the Director doesn't respond, work stops. The AI will not assume approval from lack of objection.

This might seem overly cautious, but it prevents runaway execution where the AI continues down a path you never intended. You can always grant broader approval when appropriate, but the default is to wait for explicit direction.

---

# Chapter 4: Understanding the AIXORD Formula

## The Core Transformation

At the heart of AIXORD is a simple but powerful formula that governs how work gets done:

**Project Documents → Master Scope → Deliverables → Steps → Production-Ready System**

This chain represents the transformation from initial intent to completed work. Let's break down each element:

### Project Documents

Every project begins with documentation that captures what you're trying to accomplish. This isn't bureaucracy — it's clarity. Project documents answer fundamental questions:

What is the objective?
What are the requirements?
What constraints exist?
What does success look like?

These documents become the authoritative source of truth for the project. When questions arise about what should be built, the project documents provide the answer.

### Master Scope

The Master Scope defines everything that needs to be done. It's the complete set of deliverables required to achieve the project objective.

Think of it like a bill of materials for your project. Every piece that needs to be created is listed here. Nothing gets built that isn't in scope. Nothing in scope gets forgotten.

### Deliverables

Deliverables are enumerable units of completion. Each deliverable is something you can point to and say "this is done" or "this is not done."

Good deliverables have clear boundaries. You can tell when they're complete. They produce tangible outputs that can be verified.

### Steps

Steps are the atomic units of execution. Each step is a single action that moves a deliverable forward.

Steps should be small enough to be unambiguous. If there's any question about whether a step is complete, it's probably too large and should be broken down further.

### Production-Ready System

The end result is a production-ready system that achieves the project objective. "Production-ready" means it works, it's complete, and it's suitable for its intended purpose.

## The Conservation Law

AIXORD includes a conservation principle: the total execution cannot exceed what's documented and governed. In other words, you can't have more output than input.

This prevents the AI from creating things that weren't specified. If something exists in the system, it should be traceable back to a documented requirement. If it can't be traced, it shouldn't exist.

For projects that extend existing work (brownfield projects), the conservation law ensures that verified, working functionality isn't accidentally destroyed or rebuilt unnecessarily. What exists and works should be preserved unless explicitly authorized for replacement.

---

# Chapter 5: The Three Kingdoms

## Organizing Work by Purpose

AIXORD organizes work into three "kingdoms" based on the type of activity being performed:

### Kingdom of Ideation

The Kingdom of Ideation is where exploration happens. Here you:

**Discover**: Gather information, understand the problem space, identify requirements.

**Brainstorm**: Generate options, consider alternatives, think creatively.

**Assess**: Evaluate options against criteria, understand trade-offs.

Ideation is about possibility. You're not committing to anything yet — you're exploring what could be done.

### Kingdom of Blueprint

The Kingdom of Blueprint is where decisions solidify. Here you:

**Plan**: Organize the work, sequence activities, identify dependencies.

**Specify**: Create detailed specifications for what will be built.

**Scope**: Define exactly what's in and what's out.

Blueprint transforms ideas into actionable plans. By the end of Blueprint work, you know exactly what will be built and how.

### Kingdom of Realization

The Kingdom of Realization is where things get built. Here you:

**Execute**: Actually build the deliverables according to specifications.

**Verify**: Confirm that what was built matches what was specified.

**Lock**: Finalize completed work so it can't be accidentally changed.

Realization produces tangible results. This is where specifications become reality.

## Why Kingdoms Matter

The kingdom structure prevents premature execution. You can't start building until you've finished planning. You can't finalize plans until you've explored options.

Many AI frustrations stem from skipping kingdoms. The AI jumps straight to execution without proper planning, or starts building while still exploring possibilities. AIXORD's kingdom structure enforces the discipline to do things in the right order.

---

# Chapter 6: Gates and Checkpoints

## The Gate System

Gates are checkpoints that must be satisfied before work can progress. They enforce the discipline that makes AIXORD effective.

### Why Gates Exist

Without gates, it's too easy to skip steps. You might rush into execution without proper planning. You might forget to document decisions. You might proceed without necessary approvals.

Gates make skipping impossible. If the gate isn't satisfied, work cannot proceed. Period.

### Key Gates in AIXORD

**Project Documentation Gate**: Before moving beyond brainstorming, you must have documented project requirements.

**Plan Review Gate**: Before creating a blueprint, your plan must be reviewed and approved.

**Blueprint Gate**: Before execution can begin, the blueprint must be approved and saved.

**Master Scope Gate**: Before execution, the scope must be finalized with all dependencies mapped.

**Evidence Gate**: Before work can be verified and locked, evidence of completion must be provided.

**Handoff Gate**: Before ending a session, a proper handoff document must be created.

### Artifact Requirements

Most gates require artifacts — tangible documents that exist outside the conversation. This is crucial because AI conversations are ephemeral. Messages scroll away. Context gets lost.

By requiring external artifacts, AIXORD ensures that important information persists. Your project documents, blueprints, and handoffs exist as files you control. Even if the AI forgets everything, your artifacts preserve the state.

## Checkpoint Discipline

Beyond formal gates, AIXORD encourages regular checkpoints. A checkpoint captures current state without ending the session. It's a quick save that provides a recovery point if something goes wrong.

The general guideline is to checkpoint every 15-20 messages. This isn't rigid — use judgment based on how much has happened. But regular checkpoints prevent losing significant work to session issues.

---

# Chapter 7: Working with LLaMA Models

## Understanding LLaMA

LLaMA (Large Language Model Meta AI) is Meta's family of open-weight language models. These models have become foundational in the AI ecosystem, powering countless applications and derivatives.

LLaMA models come in various sizes and configurations:

**LLaMA 2**: The second generation, available in 7B, 13B, and 70B parameter versions.

**LLaMA 3 and 3.1**: The latest generations with improved capabilities.

**Fine-tuned Variants**: Many organizations have created specialized versions tuned for specific tasks.

## The Open-Weight Advantage

LLaMA's open-weight nature means you can run these models on your own hardware. This provides:

**Privacy**: Your conversations stay on your machines.

**Control**: You choose how the model is deployed and configured.

**Customization**: You can fine-tune for your specific needs.

**Cost**: After initial hardware investment, running costs can be minimal.

## Deployment Considerations

LLaMA models can be deployed in several ways:

**Self-Hosted**: Running on your own hardware (GPU required for larger models).

**Cloud API**: Using third-party services that host LLaMA models.

**Fine-Tuned**: Using custom versions trained on specific data.

Each deployment approach has implications for how AIXORD governance applies, which we'll discuss in the next chapter.

---

# Chapter 8: LLaMA-Specific Considerations

## Understanding LLaMA's Characteristics

To work effectively with LLaMA under AIXORD governance, you need to understand the model's characteristics and how they affect collaboration.

### Instruction Following

LLaMA models, particularly base versions, require instruction tuning to follow directions well. Out of the box, they're trained to predict text, not to follow instructions.

When working with AIXORD:

Expect to be explicit. Don't assume the model will infer your intent.

Repeat important constraints. Critical instructions may need reinforcement.

Verify understanding. Ask the model to confirm what it thinks you want.

### Confidence vs. Correctness

LLaMA models can express high confidence about incorrect information. The model doesn't know what it doesn't know. A response delivered with certainty might be completely fabricated.

Under AIXORD:

Treat factual claims as unverified by default. Don't assume accuracy.

Verify critical information externally. Don't rely solely on model assertions.

Use confidence indicators. Pay attention when the model signals uncertainty.

### Context and Memory

LLaMA models have limited context windows and no persistent memory. What was discussed early in a conversation may be poorly recalled later. Information placed in the middle of a long context may be particularly unreliable.

Under AIXORD:

Use explicit artifacts. Don't rely on the model remembering previous discussions.

Re-anchor regularly. Periodically restate important constraints and objectives.

Keep critical information visible. Place important details at the start of your prompts.

### Reasoning Limitations

While capable, LLaMA models struggle with deep multi-step reasoning. Long chains of logic may break down. Complex mathematical or logical problems may produce incorrect results.

Under AIXORD:

Break down complex tasks. Divide into smaller, verifiable steps.

Use checkpoints. Verify intermediate results before proceeding.

Don't trust long reasoning chains. Verify conclusions independently.

### Safety and Alignment

Open-weight models like LLaMA have minimal built-in safety guardrails. Unlike commercial API models, they don't refuse harmful requests or detect problematic patterns reliably.

Under AIXORD:

Governance provides the guardrails. AIXORD's structure compensates for weak model alignment.

Maintain strict oversight. Don't let the model operate autonomously on sensitive tasks.

Take responsibility. You're responsible for how the model is used.

### Text-Only Nature

Most LLaMA variants are text-only. They cannot natively understand images, audio, or video.

Under AIXORD:

Don't assume multimodal capability. If your task requires processing images or other media, you'll need additional tools.

Be explicit about inputs. Describe any visual or audio content textually.

---

# Chapter 9: Getting Started: The Setup Sequence

## The Nine Steps

Every AIXORD session begins with a structured setup sequence. This isn't bureaucracy — it's ensuring that you and the AI are aligned before any work begins.

### Step 1: License Validation

AIXORD validates that you're authorized to use the framework. Enter your license email or authorization code to proceed.

### Step 2: Disclaimer Acceptance

AIXORD requires explicit acknowledgment of important terms:

You (the Director) are responsible for all decisions and outcomes.

AIXORD doesn't guarantee results.

AI may make mistakes — verify critical information.

This isn't professional advice (legal, financial, medical).

Liability is limited to purchase price.

You agree to hold PMERIT LLC harmless.

Accept by typing "I ACCEPT:" followed by your email or license code.

### Step 3: Tier Detection

Specify your platform configuration. For LLaMA, this typically includes:

Self-hosted (running on your own hardware)
Cloud API (using a hosted service)
Fine-tuned (using a custom model)

### Step 4: Environment Configuration

Confirm or modify default environment settings. For most users, accepting defaults works well.

### Step 5: Folder Structure

Choose between the standard AIXORD folder structure or your own organization system. The standard structure provides consistency; your own structure provides flexibility.

### Step 6: Citation Mode

Select how strictly sources should be cited:

STRICT: Every claim cited.
STANDARD: Key recommendations cited.
MINIMAL: Sources on request only.

### Step 7: Continuity Mode

Choose your session management approach:

STANDARD: Normal conversational continuity.
STRICT-CONTINUITY: Enforced handoffs and recovery commands.
AUTO-HANDOFF: Automatic handoff on risk or ambiguity.

### Step 8: Project Objective

Declare your project objective in one or two sentences. This becomes the north star for all work in the session.

### Step 9: Reality Classification

Specify whether this project:

GREENFIELD: Starting fresh with no existing work.
BROWNFIELD-EXTEND: Extending existing verified work.
BROWNFIELD-REPLACE: Replacing existing work.

For brownfield projects, list what existing work should be preserved or replaced.

## After Setup

Once all nine steps complete, you'll see a session configuration summary. This locks in your choices for the session. Now you're ready to begin actual work.

---

# Chapter 10: Day-to-Day Operations

## Starting a Session

When returning to continue work, use the command "PMERIT CONTINUE" to resume from your last state. The AI will look for your handoff document and restore context.

## Giving Direction

As Director, you guide the work by stating what you want to accomplish. Be specific about:

What outcome you're seeking.
What constraints exist.
What quality level is required.
What timeline you're working with.

## Reviewing Recommendations

The AI in Architect mode will recommend approaches. Review these carefully. Look for:

Alignment with your objectives.
Feasibility given your constraints.
Completeness — are important aspects covered?
Risks — what could go wrong?

## Granting Approval

When satisfied with a recommendation, grant explicit approval using the approval grammar. Be specific about what you're approving.

## Monitoring Execution

When the AI executes, monitor progress. Check that execution matches specifications. Raise concerns immediately rather than waiting until the end.

## Handling Problems

If execution goes off track:

Use HALT to stop work immediately.
Diagnose what went wrong.
Decide whether to retry, revise the approach, or step back to planning.

## Ending Sessions

Always end sessions properly with a handoff. The HANDOFF command generates a document that captures current state, enabling clean resumption later.

---

# Chapter 11: Quality Assurance

## The Seven Quality Dimensions

AIXORD defines seven dimensions against which every deliverable is assessed:

### Best Practices

Does the work follow industry-standard approaches? Are established patterns and conventions used appropriately?

### Completeness

Are all requirements addressed? Are there gaps in functionality or coverage?

### Accuracy

Is the work factually correct? Are calculations right? Are claims verifiable?

### Sustainability

Can the work be maintained long-term? Is it built for durability or just immediate functionality?

### Reliability

Does the work handle errors and edge cases? Will it work consistently in real conditions?

### User-Friendliness

Is the work intuitive and well-documented? Can others understand and use it?

### Accessibility

Is the work inclusive? Does it accommodate diverse users and use cases?

## Quality Assessment

Before work can be verified and locked, it must pass quality assessment. Each dimension is evaluated as:

**PASS**: Meets standards with evidence.
**ACCEPTABLE**: Adequate with acknowledged trade-offs.
**FAIL**: Does not meet standards — blocks progression.

Any FAIL blocks verification unless you explicitly waive the requirement. This isn't arbitrary strictness — it ensures quality issues are addressed rather than ignored.

## Evidence Requirements

Quality claims must be supported by evidence. The AI can't simply assert "PASS" — there must be justification. This prevents rubber-stamping and ensures real quality.

---

# Chapter 12: Session Management and Continuity

## The Continuity Problem

AI conversations are inherently ephemeral. The model has no persistent memory. When a session ends, everything discussed is effectively forgotten.

AIXORD addresses this through structured continuity mechanisms.

## Handoff Documents

A handoff document captures everything needed to resume work in a new session:

Current state (phase, kingdom, gates completed).
Active deliverables and their status.
Recent decisions and their rationale.
Artifact locations.
Explicit next action.
Recovery instructions.

## Creating Handoffs

At session end, use the HANDOFF command. The AI will generate a handoff document. Save this file externally — it's your continuity lifeline.

## Resuming from Handoffs

In a new session, provide your handoff document to the AI. Use PMERIT CONTINUE to restore state. The AI will ask to verify artifact bindings before proceeding.

## Checkpoints vs. Handoffs

Checkpoints are quick saves within a session. They capture state but don't produce full handoff documents. Use checkpoints regularly during work.

Handoffs are complete session endings. They produce full documentation and are required when you'll be stepping away from work.

## Handling Lost Context

If context is lost (session crashes, long gaps between work), use PMERIT RECOVER to rebuild state. This requires your handoff document and may require re-verifying artifact bindings.

---

# Chapter 13: Troubleshooting Common Issues

## The AI Ignores My Instructions

LLaMA models may not follow instructions reliably, especially without proper tuning.

**Solution**: Be more explicit. Repeat critical constraints. Ask the AI to confirm understanding before proceeding.

## The AI Makes Things Up

Hallucination is a known issue with LLaMA models. The AI may fabricate facts, citations, or reasoning.

**Solution**: Treat all factual claims as unverified. Validate important information externally. Use low confidence indicators as warning signs.

## Work Gets Done That I Didn't Approve

This shouldn't happen under AIXORD governance, which requires explicit approval.

**Solution**: Reinforce the approval requirement. Only use explicit approval grammar. Call out unauthorized work immediately.

## I Can't Pick Up Where I Left Off

Context loss between sessions is a fundamental challenge.

**Solution**: Always create handoffs before ending sessions. Keep artifact files current. Use recovery commands when resuming.

## Quality Is Inconsistent

Without structure, AI output quality varies significantly.

**Solution**: Use quality assessments. Require evidence for quality claims. Don't accept work that doesn't meet standards.

## The AI Expands Scope Without Permission

Scope creep is common when AI enthusiastically adds features or considerations.

**Solution**: Enforce scope boundaries explicitly. Reject out-of-scope additions immediately. Require explicit scope expansion commands.

## Complex Tasks Break Down

LLaMA struggles with deep multi-step reasoning.

**Solution**: Break complex tasks into smaller steps. Verify intermediate results. Use checkpoints frequently.

---

# Chapter 14: Best Practices for LLaMA Users

## Start Every Session Clean

Always go through the setup sequence. It only takes a few minutes and ensures proper alignment.

## Be Explicit About Everything

Don't assume the model will infer your intent. State requirements clearly. Repeat important constraints.

## Verify, Verify, Verify

Treat model outputs as drafts requiring verification. Check facts. Review logic. Test functionality.

## Keep Artifacts Current

Your external files are your source of truth. Keep them updated. Don't let discrepancies accumulate.

## Checkpoint Regularly

Save state frequently. The cost of checkpointing is low; the cost of lost work is high.

## Respect the Kingdoms

Do ideation work in ideation. Do planning work in blueprint. Do execution work in realization. Don't mix them.

## Use Gates as Guardrails

Gates aren't obstacles — they're quality gates. Embrace them as protection against rushed or incomplete work.

## End Sessions Properly

Always create handoffs. Future you will thank present you.

## Know the Limitations

Understand what LLaMA does well and where it struggles. Work with the model's strengths; compensate for its weaknesses.

## Take Responsibility

You're the Director. The outcomes are yours. AIXORD helps you maintain control, but the responsibility is yours.

---

# Chapter 15: Quick Reference Guide

## Essential Commands

| Command | Effect |
|---------|--------|
| PMERIT CONTINUE | Start/resume session |
| APPROVED | Authorize proposed action |
| APPROVED: [scope] | Authorize specific scope |
| EXECUTE | Direct authorization |
| HALT | Stop all work |
| CHECKPOINT | Quick save, continue |
| HANDOFF | Full save, end session |
| SHOW STATE | Display current state |

## Approval Grammar

**Valid approvals that grant execution authority:**
- APPROVED
- APPROVED: [specific scope]
- EXECUTE
- DO IT
- YES, PROCEED

**Invalid — require clarification:**
- Looks good
- Fine / OK / Sure
- Thumbs up
- Silence

## The Formula

Project_Docs → Master_Scope → Deliverables → Steps → Production-Ready System

## Three Kingdoms

1. **IDEATION**: Discover, Brainstorm, Assess
2. **BLUEPRINT**: Plan, Specify, Scope
3. **REALIZATION**: Execute, Verify, Lock

## Quality Dimensions

1. Best Practices
2. Completeness
3. Accuracy
4. Sustainability
5. Reliability
6. User-Friendliness
7. Accessibility

## LLaMA Considerations

- Verify all factual claims externally
- Be explicit; repeat constraints
- Break complex tasks into steps
- Checkpoint frequently
- Expect text-only capability

---

# Chapter 16: Appendix: Product Information

## About This Product

**Product Name**: AIXORD for LLaMA — Meta AI Governance

**Version**: 4.2

**Price**: $29.99

**Discount Code**: AX-LLM-2M6Y (promotional)

**Store URL**: https://meritwise0.gumroad.com/l/xtwqj

## What's Included

This package includes:

**This Educational Manuscript**: The document you're reading, explaining AIXORD concepts and LLaMA-specific considerations.

**AI Operational Core File**: The governance file to be used with LLaMA-based AI systems.

**Legal Documents**: LICENSE.md and DISCLAIMER.md establishing terms of use.

**Tools ZIP**: Optional convenience assets including folder structure templates.

## License Terms

This product is licensed for up to 2 authorized email addresses. See LICENSE.md for complete terms.

## Support

For support questions, contact: support@pmerit.com

For product information, visit: https://pmerit.gumroad.com

## About PMERIT

PMERIT (People Merit) develops frameworks and tools for productive human-AI collaboration. AIXORD is our flagship governance methodology, designed to bring structure and accountability to AI-assisted work.

## Other AIXORD Products

AIXORD is available for multiple AI platforms:

- AIXORD for ChatGPT — OpenAI AI Governance
- AIXORD for Claude — Anthropic AI Governance
- AIXORD for Gemini — Google AI Governance
- AIXORD for DeepSeek — DeepSeek AI Governance
- AIXORD for Copilot — Microsoft AI Governance
- AIXORD for Grok — xAI Governance
- AIXORD for Mistral — Mistral AI Governance
- AIXORD for Perplexity — Perplexity AI Governance
- AIXORD for Command R+ — Cohere AI Governance
- AIXORD for Phi — Microsoft Open-Weight Governance
- AIXORD for Gemma — Google Open-Weight Governance
- AIXORD Builder Bundle — Complete Framework Package

Visit https://pmerit.gumroad.com for the full product catalog.

---

# Chapter 17: Advanced Techniques

## Multi-Session Project Management

Large projects often span many sessions over days or weeks. AIXORD provides the framework for managing this complexity.

### Session Planning

Before beginning a multi-session project, consider:

**Scope Division**: How will the work be divided across sessions? What are logical stopping points?

**Artifact Strategy**: What documents will you maintain? Where will they be stored? How will they be updated?

**Handoff Cadence**: How frequently will you create full handoffs versus quick checkpoints?

**Recovery Planning**: If something goes wrong, how will you recover? What are your backup points?

### Maintaining Momentum

Long projects face the challenge of maintaining momentum across sessions. Each return requires context restoration. Each handoff carries the risk of lost nuance.

Strategies for maintaining momentum:

**Consistent Naming**: Use consistent file and artifact naming conventions. This reduces confusion when resuming.

**Explicit State Tracking**: Keep a running log of decisions, even small ones. What seems obvious today may be unclear next week.

**Regular Reviews**: Periodically step back and review the overall project state. Are you still on track? Have requirements changed?

**Clean Breaks**: End sessions at natural stopping points. Don't leave work in ambiguous states.

### Handling Project Evolution

Projects change over time. Requirements evolve. New information emerges. AIXORD provides mechanisms for controlled evolution:

**Scope Expansion Commands**: Use explicit commands to expand scope rather than allowing gradual creep.

**Change Documentation**: Document why changes were made, not just what changed.

**Impact Assessment**: When scope changes, assess impact on existing work before proceeding.

**Version Control**: Maintain versions of key documents so you can track evolution.

## Working with Multiple AI Sessions

Sometimes you might work with different AI instances or even different models during a project. AIXORD enables this through its artifact-centric approach.

### Artifact Portability

Because AIXORD governance lives in artifacts rather than AI memory, you can:

Transfer work between different AI sessions.
Resume with different instances of the same model.
Even move between different AI platforms (with appropriate variant files).

The key is maintaining accurate, complete artifacts that capture all essential state.

### Instance Independence

Each AI instance starts fresh. Never assume an AI "remembers" anything from previous sessions. Always:

Provide handoff documents explicitly.
Verify artifact bindings before proceeding.
Re-establish context through the recovery process.

### Team Collaboration

In team settings where multiple people work with AI on the same project:

Establish a single source of truth for project artifacts.
Use clear handoff naming that includes dates and authors.
Maintain a project log accessible to all team members.
Define roles and responsibilities for artifact maintenance.

## Performance Optimization

Getting the best results from LLaMA under AIXORD requires understanding how to optimize the interaction.

### Prompt Construction

Even within AIXORD's structured framework, prompt quality matters:

**Front-Load Critical Information**: Place the most important context at the beginning of your prompts. LLaMA's attention degrades toward the middle of long contexts.

**Use Explicit Markers**: Clear section headers and markers help the model parse your input correctly.

**Be Specific**: Vague requests produce vague responses. Specific requests produce specific responses.

**Provide Examples**: When possible, show what you want rather than just describing it.

### Context Management

LLaMA's context window is finite. Managing it well improves results:

**Prune Irrelevant History**: Don't keep accumulating context indefinitely. Summarize and archive older material.

**Use Artifacts for Reference**: Rather than keeping everything in the conversation, point to external artifacts.

**Focused Sessions**: Keep individual sessions focused on specific tasks rather than trying to cover everything.

### Model Selection

Different LLaMA variants have different capabilities:

**Larger Models**: Generally more capable but require more resources. Use when task complexity warrants it.

**Smaller Models**: Faster and lighter. Suitable for simpler tasks or resource-constrained environments.

**Instruction-Tuned Variants**: Better at following directions. Generally preferred for AIXORD work.

**Domain-Specific Tunes**: If available for your domain, may provide better results than general models.

## Integration with Other Tools

AIXORD doesn't exist in isolation. It integrates with your broader workflow.

### Version Control Systems

AIXORD artifacts are files that can be version-controlled:

Store artifacts in Git or similar systems.
Track changes over time.
Enable collaboration and review.
Maintain history for auditing.

### Project Management Tools

AIXORD deliverables can map to project management constructs:

Each deliverable can become a task or story.
Gates align with quality gates or acceptance criteria.
Phases map to project phases or sprints.

### Documentation Systems

AIXORD outputs are documentation:

Project documents become requirements documents.
Blueprints become design documents.
Handoffs become status reports.

### Development Workflows

For software projects:

AIXORD specifications inform code implementation.
Quality dimensions align with code review criteria.
Verified deliverables become release candidates.

---

# Chapter 18: Case Studies

## Case Study 1: Software Feature Development

**Scenario**: A developer needs to add a user authentication system to an existing web application.

**AIXORD Application**:

Setup established the project as BROWNFIELD-EXTEND, conserving the existing application architecture.

Ideation phase explored authentication approaches: session-based, JWT, OAuth, etc.

Blueprint phase produced detailed specifications for JWT-based authentication.

Gates ensured specifications were complete before implementation began.

Execution phase implemented the feature according to specifications.

Quality assessment verified security best practices, completeness, and documentation.

Lock phase finalized the feature for deployment.

**Outcome**: The authentication system was delivered on specification, with clear documentation and verified security practices. The multi-session project maintained continuity through handoffs.

## Case Study 2: Research Report

**Scenario**: A researcher needs to produce a comprehensive literature review on a specialized topic.

**AIXORD Application**:

Setup established GREENFIELD project for the new report.

Ideation phase identified key themes, relevant papers, and research questions.

Blueprint phase structured the report outline with sections and subsections.

Gates required the outline to be approved before writing began.

Execution phase produced content section by section, with checkpoints.

Quality assessment verified accuracy of citations, completeness of coverage, and clarity of presentation.

Handoffs enabled the multi-week project to maintain consistency.

**Outcome**: The literature review was comprehensive, well-organized, and accurately cited. The structured approach prevented the common problem of reports that wander or miss key sources.

## Case Study 3: Business Process Design

**Scenario**: An entrepreneur needs to design operational processes for a new business.

**AIXORD Application**:

Ideation explored different process approaches and identified requirements.

Multiple sessions covered different operational areas: customer onboarding, fulfillment, support, etc.

Blueprints produced detailed process definitions with decision points and exception handling.

Quality assessment ensured processes were sustainable, reliable, and user-friendly.

Artifacts created a comprehensive operations manual.

**Outcome**: The business launched with well-defined processes that could be trained to staff and refined over time. The documentation provided a foundation for future improvements.

---

# Chapter 19: Frequently Asked Questions

## About AIXORD

**Q: What does AIXORD stand for?**
A: AI Execution Order — adapted from military OPORD (Operations Order) methodology.

**Q: Is AIXORD specific to LLaMA?**
A: No. AIXORD is a methodology that works with many AI platforms. This variant is adapted for LLaMA's specific characteristics.

**Q: Do I need technical skills to use AIXORD?**
A: Basic familiarity with AI assistants is helpful, but AIXORD is designed for users at all technical levels. The methodology itself is straightforward.

## About LLaMA

**Q: Which LLaMA version should I use?**
A: AIXORD works with all LLaMA variants. Larger, instruction-tuned models generally provide better results but require more resources.

**Q: Can I use AIXORD with LLaMA fine-tunes?**
A: Yes. AIXORD governance applies regardless of how the model was trained.

**Q: Does AIXORD work with self-hosted LLaMA?**
A: Absolutely. Self-hosted deployment is a common use case.

## About Governance

**Q: Why so much structure?**
A: Structure prevents the common frustrations of AI work: lost context, scope creep, quality inconsistency. The overhead pays for itself in reduced rework and frustration.

**Q: Can I skip parts of AIXORD?**
A: AIXORD is designed as an integrated system. Skipping parts reduces effectiveness. That said, simpler tasks can use simpler governance through the task classification system.

**Q: What if the AI doesn't follow AIXORD?**
A: Reinforce the governance explicitly. LLaMA may need repeated instruction. If governance consistently fails, verify your model is adequately instruction-tuned.



---

## Additional AIXORD Concepts

The following sections provide deeper coverage of key AIXORD concepts that apply across all AI platforms.


### The Seven Quality Dimensions

AIXORD includes a comprehensive quality assessment framework that evaluates every deliverable across seven dimensions. This framework ensures professional-grade output regardless of which AI assistant you use.

**Dimension 1: Best Practices**

Every deliverable must follow industry-standard approaches. This means using established patterns, following security guidelines, and applying proven methodologies. AI assistants are instructed to aggregate their knowledge and proactively apply best practices rather than waiting for you to specify them.

**Dimension 2: Completeness**

All requirements must be addressed. A deliverable cannot be marked complete if it only partially fulfills the specification. AIXORD forces explicit tracking of requirements against implementation.

**Dimension 3: Accuracy**

Information must be factually correct and verified. When certainty varies, AIXORD requires the AI to communicate confidence levels:
- HIGH confidence: Multiple authoritative sources confirm
- MEDIUM confidence: Single source or inference
- LOW confidence: AI reasoning only
- UNVERIFIED: Recommend external verification

**Dimension 4: Sustainability**

Deliverables must be maintainable long-term. This dimension evaluates whether the work can be understood, modified, and extended by others. Code without documentation, clever but obscure solutions, and tightly coupled components fail sustainability assessment.

**Dimension 5: Reliability**

Work must handle errors and edge cases gracefully. Systems that crash under unusual conditions, ignore error states, or assume perfect inputs fail reliability assessment.

**Dimension 6: User-Friendliness**

Output must be intuitive and well-documented. Technical excellence means nothing if users cannot understand or use the result effectively.

**Dimension 7: Accessibility**

Deliverables must follow inclusive design principles. This applies to documentation, interfaces, and any user-facing components.

**Quality Enforcement**

Any dimension marked FAIL blocks progression unless the Director explicitly accepts the trade-off. Each assessment requires evidence or justification — unsupported "PASS" ratings are invalid.


---

## Additional AIXORD Concepts

The following sections provide deeper coverage of key AIXORD concepts that apply across all AI platforms.


### The Seven Quality Dimensions

AIXORD includes a comprehensive quality assessment framework that evaluates every deliverable across seven dimensions. This framework ensures professional-grade output regardless of which AI assistant you use.

**Dimension 1: Best Practices**

Every deliverable must follow industry-standard approaches. This means using established patterns, following security guidelines, and applying proven methodologies. AI assistants are instructed to aggregate their knowledge and proactively apply best practices rather than waiting for you to specify them.

**Dimension 2: Completeness**

All requirements must be addressed. A deliverable cannot be marked complete if it only partially fulfills the specification. AIXORD forces explicit tracking of requirements against implementation.

**Dimension 3: Accuracy**

Information must be factually correct and verified. When certainty varies, AIXORD requires the AI to communicate confidence levels:
- HIGH confidence: Multiple authoritative sources confirm
- MEDIUM confidence: Single source or inference
- LOW confidence: AI reasoning only
- UNVERIFIED: Recommend external verification

**Dimension 4: Sustainability**

Deliverables must be maintainable long-term. This dimension evaluates whether the work can be understood, modified, and extended by others. Code without documentation, clever but obscure solutions, and tightly coupled components fail sustainability assessment.

**Dimension 5: Reliability**

Work must handle errors and edge cases gracefully. Systems that crash under unusual conditions, ignore error states, or assume perfect inputs fail reliability assessment.

**Dimension 6: User-Friendliness**

Output must be intuitive and well-documented. Technical excellence means nothing if users cannot understand or use the result effectively.

**Dimension 7: Accessibility**

Deliverables must follow inclusive design principles. This applies to documentation, interfaces, and any user-facing components.

**Quality Enforcement**

Any dimension marked FAIL blocks progression unless the Director explicitly accepts the trade-off. Each assessment requires evidence or justification — unsupported "PASS" ratings are invalid.



### Task Classification System

Not every task requires full AIXORD ceremony. The framework recognizes that a simple typo fix shouldn't require the same governance as a platform migration.

**TRIVIAL Tasks**

Criteria: Less than 5 minutes, fully reversible, no dependencies.
Required governance: Director approval only.
Example: "Fix typo in README"

**SIMPLE Tasks**

Criteria: Less than 1 hour, single deliverable.
Required governance: Deliverable definition plus steps.
Example: "Add logout button"

**STANDARD Tasks**

Criteria: Multiple deliverables with dependencies.
Required governance: Full AIXORD formula.
Example: "Build authentication system"

**COMPLEX Tasks**

Criteria: Multi-session, high risk, significant dependencies.
Required governance: Full formula plus risk assessment.
Example: "Platform migration"

The classification flow works as follows:
1. AI proposes task class based on scope analysis
2. Director confirms or overrides the classification
3. Classification is recorded in STATE
4. Governance scales accordingly

This prevents the framework from becoming bureaucratic overhead while ensuring complex work receives appropriate structure.



### Artifact Binding and Persistence

One of the most critical concepts in AIXORD is artifact binding. This addresses a fundamental limitation of AI chat systems: they do not reliably persist files or remember generated content across sessions.

**The Core Problem**

When you ask an AI to create a document, that document exists only in the chat window. If you start a new session, the AI has no memory of what it created. If the platform loses the conversation, the document is gone.

Worse, many AI systems will confidently act as if they remember files they generated previously. They will reference non-existent documents, claim to see folder structures that were never created, and proceed with work based on artifacts that no longer exist.

**The Artifact Binding Solution**

AIXORD requires explicit artifact binding. This means:

1. When the AI generates any artifact intended for future use, it must instruct you to save it externally
2. You must confirm the save before the AI considers the artifact "bound"
3. On resume, all artifacts must be re-bound by providing confirmation they still exist
4. The AI cannot act on unbound artifacts

**Binding Methods**

AIXORD accepts several confirmation methods:
- VISUAL: Screenshot or file explorer image showing the saved file
- TEXTUAL: Pasting the file contents or directory listing
- HASH: Providing a cryptographic hash of the file
- PLATFORM: Sharing a link (Google Drive, GitHub, Dropbox)
- ATTESTATION: Simple statement that the file was saved (low assurance)

**Why This Matters**

Without artifact binding, AI conversations eventually collapse. The AI makes assumptions about what exists, acts on those assumptions, and produces work that conflicts with reality. Artifact binding prevents this failure mode by requiring explicit verification.


## About Practical Usage

**Q: How long does setup take?**
A: The nine-step setup typically takes a few minutes. It's an investment that pays dividends throughout the session.

**Q: How often should I checkpoint?**
A: Every 15-20 messages is a good guideline. More frequently if doing complex or risky work.

**Q: What if I lose my handoff document?**
A: Without a handoff, resumption is difficult. You'll need to reconstruct state from other artifacts or start fresh. This is why maintaining handoffs is critical.

---

# Closing Thoughts

AIXORD for LLaMA brings structured governance to the open-weight AI ecosystem. By combining the flexibility of self-hosted models with the discipline of explicit authority, gates, and quality standards, you can achieve reliable, repeatable results from your AI collaborations.

The framework requires investment — in learning the methodology, in maintaining artifacts, in disciplined session management. But this investment pays dividends in reduced frustration, fewer lost efforts, and higher quality outcomes.

Remember: chaos is optional. With AIXORD, you have the tools to bring order to your AI workflows. The choice of how to use them is yours.

Thank you for choosing AIXORD. May your AI collaborations be productive, your context never lost, and your outcomes always meet your standards.

---

**AIXORD v4.2 — Authority. Formula. Conservation. Verification.**

*Adapted for Meta LLaMA Family*

---

© 2026 PMERIT LLC. All rights reserved.

This material is protected under applicable copyright law. Unauthorized reproduction or distribution is prohibited.
